{
  "module_locations": [
    "apps/worker/src/pipeline.ts",
    "apps/worker/src/worker.ts",
    "packages/core/src/semantic-structure.ts",
    "packages/core/src/semantic-metadata.ts",
    "packages/core/src/ocr.ts",
    "apps/api/src/routes.ts",
    "packages/shared-schemas/src/index.ts",
    "docs/ingestion.md",
    "docs/retrieval.md"
  ],
  "current_state": {
    "semantic_segmentation": "Worker 使用 generateStructureViaModel  model_settings 配置了 role=structure r⒂茫生成 title/level/path/content 的 sections Kc chunks 合悖蝗鄙僭O定r回退 AdaptiveChunkFactory 按L度切分。",
    "chunk_metadata": "extractMetadata 使用 generateSemanticMetadataViaModel (role=metadata) 生成 title/summary/semanticTags/topics/keywords/envLabels/bizEntities/entities/parentSectionPath，K落斓 chunk.semanticMetadata；provider=local r做l式摘要，oO定r跳^。",
    "structure_tree": "normalizeSemanticSections a生 document_sections，chunk.parentSectionPath c sectionId 定；GET /documents/:id/structure 返回Zx蛹。",
    "retrieval": "HybridRetriever (packages/core/src/retrieval.ts) 供 /search 及 MCP kb.search/related/preview，支持 semanticTags/envLabels/attachment filters，返回 chunk+document+attachments。",
    "ocr": "shouldUseOcr 覆w pdf/image/doc/ppt/xls；HttpOcrAdapter/LocalOcrAdapter 由 OCR_* h境量樱提取文本後走同一切分流程。",
    "pipeline_flow": "upload -> queue -> preprocessRawText -> semanticSegmenter -> metadata -> embed -> persist (documents/chunks/sections/embeddings/attachments)。"
  },
  "tech_stack": "Bun + TypeScript，pgvector/Qdrant/MinIO/RabbitMQ；LLM provider openai/ollama  model_settings 配置，默J⒂ Xenova 本地模型；OCR 支持本地命令或 HTTP。",
  "tests": "apps/api/src/__tests__/api.test.ts 覆w /mcp/search|related|preview；未ｉT的Zx切分/元 e2e y。",
  "observations": [
    "LLM 切分/元依 model_settings role=structure/metadata；倘缺失tH按L度切分且oZx俗。",
    "SEMANTIC_METADATA_LIMIT 控制 LLM {用担默J不限制。",
    "OCR_ENABLED=false 或未配置 adapter r不做 OCR。",
    "]有 model_settings N子，需 /model-settings API 或直接炫渲谩"
  ]
}
